{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import nltk\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = pd.read_csv(\"../professionals.csv\")\n",
    "answ = pd.read_csv(\"../answers.csv\")\n",
    "stud = pd.read_csv(\"../students.csv\")\n",
    "ques = pd.read_csv(\"../questions.csv\")\n",
    "emai = pd.read_csv(\"../emails.csv\")\n",
    "matc = pd.read_csv(\"../matches.csv\")\n",
    "tagq = pd.read_csv(\"../tag_questions.csv\")\n",
    "taqu = pd.read_csv(\"../tag_users.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where professionals and students are from (locations and number). Which locations have both professionals and students. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York, New York            1337\n",
      "California, California         864\n",
      "Greater New York City Area     745\n",
      "Boston, Massachusetts          714\n",
      "Los Angeles, California        617\n",
      "Atlanta, Georgia               578\n",
      "Chicago, Illinois              576\n",
      "Austin, Texas                  574\n",
      "Houston, Texas                 556\n",
      "San Francisco Bay Area         513\n",
      "Name: professionals_location, dtype: int64\n",
      "\n",
      "\n",
      "New York, New York             1313\n",
      "Bengaluru, Karnataka, India     890\n",
      "Los Angeles, California         663\n",
      "Hyderabad, Telangana, India     597\n",
      "Boston, Massachusetts           557\n",
      "San Francisco, California       550\n",
      "San Jose, California            548\n",
      "Houston, Texas                  476\n",
      "Chennai, Tamil Nadu, India      437\n",
      "Chicago, Illinois               344\n",
      "Name: students_location, dtype: int64\n",
      "\n",
      "These are the locations with both professionals and students: ['Abilene, Texas' 'Abu Dhabi, United Arab Emirates' 'Abuja, FCT, Nigeria'\n",
      " ... 'York, Pennsylvania' 'Ypsilanti, Michigan' 'nan']\n",
      "\n",
      "In total, there are 1381 locations with both professional and students\n"
     ]
    }
   ],
   "source": [
    "print(prof.professionals_location.value_counts().head(10))\n",
    "print(\"\\n\")\n",
    "print(stud.students_location.value_counts().head(10))\n",
    "\n",
    "p_loc = np.array(prof['professionals_location'].values.tolist())\n",
    "s_loc = np.array(stud['students_location'].values.tolist())\n",
    "\n",
    "i = np.intersect1d(p_loc,s_loc)\n",
    "print(\"\\nThese are the locations with both professionals and students: {}\".format(i))\n",
    "print(\"\\nIn total, there are {} locations with both professional and students\".format(i.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which industries are most of these professionals in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Telecommunications                     3166\n",
       "Information Technology and Services    2109\n",
       "Computer Software                      1272\n",
       "Hospital and Health Care                862\n",
       "Higher Education                        800\n",
       "Accounting                              781\n",
       "Financial Services                      639\n",
       "Education Management                    593\n",
       "Marketing and Advertising               526\n",
       "Internet                                427\n",
       "Name: professionals_industry, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.professionals_industry.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are key words (NN) from students' questions? First strip html tags from answers and questions and access the nouns using nltk.tag_pos() and nltk.word_tokenizer()\n",
    "\n",
    "Here we can then plot all the different NN* to see what words are \"big\" in students' questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This class strips all HTML encoding in the responses \n",
    "## It takes in a string and returns an HTML-free string\n",
    "## Usage: strip_tags(df.text_body.iloc[i]) for i in range(0:df.size)\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "    \n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('joined', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('Army', 'NNP'),\n",
       " ('after', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('attended', 'VBD'),\n",
       " ('college', 'NN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (answ.answers_body.iloc[1])\n",
    "\n",
    "\n",
    "a = strip_tags(a)\n",
    "\n",
    "\n",
    "### tokenize the answers and then classify parts of speech. Keep words that are NN\n",
    "### Make a dictionary to update the frequency of these individual words across all words. \n",
    "b = (nltk.pos_tag(nltk.word_tokenize(a)))\n",
    "\n",
    "b[1:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
